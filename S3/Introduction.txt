S3(Simple Storage Service)
    - uses 
        - Backup and Storage 
        - Disaster Recovery
        - Archive
        - Hybrid Cloud storage
        - Application hosting
        - Media hosting
        - Data lakes and big data analystics
        - Software delivery
        - static website
    - Stores objects/files in buckets
    - bucket must have globally unique name
    - buckets are defined at the regional level
    - Objects(files) have a Key - A key is the full path of the bucket.
        - s3://my-bucket/<path_to_bucket> (path is the key).
    - There is no concept of directories within buckets there are just keys with long names.
    - Max object size is 5TB (5000 GB)
    - If uploading file more than 5TB size use `multi-part-upload`
    - Metadata - list of key-value pairs
    - Tags - Unicode key/value pair - useful for security.
    - Version ID on objects (If version enabled)

S3 Security
    - IAM policies - which API calls should be allow from a specific user
    - Bucket policy - Control access to the bucket
    - Object Access Control List(ACL) - fined grained
    - Bucket Access Control List(ACL)
    - Encryption - encrypt objects using encryption keys

S3 can host static websites and have them accessible on the internet.
    - we need to enable the static webiste option in properties.
    
We can version the files in amazon S3
    - It is enabled at the bucket level
    - protect against unintended delete
    - rollback to previous version

S3 Replication
    - cross region replication(CRR) and same region replication (SRR)
    - Buckets can be in different aws accounts.
    - the replication is asynchronous.
    - It requires proper permissions given to the bucket.
    - after enabling replication only new objects will be replicated if we want to replicate existing objects then use S3 Batch Replication.
    - there is no replication chaining , 1 replicate to 2 , 2 replicate to 3 , then 1 not replicate to 3.
    - replication only works if versioning is enable.

S3 Storage Classes
    - Amazon S3 standard-general purpose
        - 99.99% availability
        - frequently accessed data storage
        - low latency and high throughput
        - sustain 2 concurrent facility failures.
    - standard-infrequent-access
        - less frequently accesses data 
        - requires rapid access when needed
        - lower cost than s3 standard and retrieval cost
    - one zone-infrequent access
        - high durability in a single AZ 
        - data loss when AZ destroyed.
    - glacier storage classes - low cost storage meant for archiving/Backup
        -  glacier instant retrieval
            - millisecond retrieval
            - minimum storage duration of 90 days
        -  glacier flexible retrieval
            - expedited - 1 to 5 mins 
            - standard - 3 to 5 hours
            - bulk - 5 to 12 hours  - free
            - minimum storage duration is 90 days
        -  glacier deep Archive
            - for long term storage
            - standard - 12 hours
            - bulk - 48 hours
            - minimum storage duration of 180 days
            - lowest cost
    - Intelligent tiering
        - move objects automatically between access tiers baaed on usage.
        - small monthly monitoring and auto-tiering fee 
        - no retrieval charges
    - S3 Express one zone 
        - High performance
        - single AZ
        - object stored in directory bucket
        - reduced latency

Can move between classes manually or using lifecycle configurations.


